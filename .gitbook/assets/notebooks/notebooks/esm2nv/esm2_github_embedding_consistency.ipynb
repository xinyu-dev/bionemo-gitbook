{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESM2 Github Embedding Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import esm\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show ESM2 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: fair-esm\n",
      "Version: 2.0.0\n",
      "Summary: Evolutionary Scale Modeling (esm): Pretrained language models for proteins. From Facebook AI Research.\n",
      "Home-page: https://github.com/facebookresearch/esm\n",
      "Author: Facebook AI Research\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: \n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show fair-esm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_esm_main\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", \"esm2_t33_650M_UR50D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-32): 33 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): ESM1bLayerNorm(torch.Size([1280]), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): ESM1bLayerNorm(torch.Size([1280]), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): ESM1bLayerNorm(torch.Size([1280]), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): ESM1bLayerNorm(torch.Size([1280]), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval().cuda()  # disables dropout for deterministic results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test embedding consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    }
   ],
   "source": [
    "short_seq = ('short_seq', 'MQLYLVLLLISYLLTPIGASILGRCTVAKMLYDGGLNYFEGYSLENWVCLAYFESKFNPSAVYEDPQDGSTGFGLFQIRDNEWCGHGKNLCSVSCTALLNPNLKDTIQCAKKIVKGKHGMGAWPIWSKNCQLSDVLDRWLDGCDL')\n",
    "long_seq = ('long_seq', 'MKWVTFISLLLLFSSAYSRGVFRRDTHKSEIAHRFKDLGEEHFKGLVLIAFSQYLQQCPFDEHVKLVNELTEFAKTCVADESHAGCEKSLHTLFGDELCKVASLRETYGDMADCCEKQEPERNECFLSHKDDSPDLPKLKPDPNTLCDEFKADEKKFWGKYLYEIARRHPYFYAPELLYYANKYNGVFQECCQAEDKGACLLPKIETMREKVLASSARQRLRCASIQKFGERALKAWSVARLSQKFPKAEFVEVTKLVTDLTKVHKECCHGDLLECADDRADLAKYICDNQDTISSKLKECCDKPLLEKSHCIAEVEKDAIPENLPPLTADFAEDKDVCKNYQEAKDAFLGSFLYEYSRRHPEYAVSVLLRLAKEYEATLEECCAKDDPHACYSTVFDKLKHLVDEPQNLIKQNCDQFEKLGEYGFQNALIVRYTRKVPQVSTPTLVEVSRSLGKVGTRCCTKPESERMPCTEDYLSLILNRLCVLHEKTPVSEKVTKCCTESLVNRRPCFSALTPDETYVPKAFDEKLFTFHADICTLPDTEKQIKKQTALVELLKHKPKATEEQLKTVMENFVAFVDKCCAADDKEACFAVEGPKLVVSTQTALA')\n",
    "\n",
    "input1 = [short_seq]\n",
    "input2 = [short_seq, short_seq]\n",
    "input3 = [short_seq, long_seq]\n",
    "\n",
    "print(len(short_seq[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    \"\"\"\n",
    "    Generate per-residue representations for a batch of sequences.\n",
    "    :param data: list of tuples (sequence_id, sequence)\n",
    "    \"\"\"\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "    # add to GPU\n",
    "    batch_tokens = batch_tokens.to('cuda')\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    return token_representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = predict(input1)[0].cpu()\n",
    "result2a = predict(input2)[0].cpu() # same seq, at index 0 in the array\n",
    "result2b  = predict(input2)[1].cpu() # same seq, at index 1 in the array\n",
    "result3 = predict(input3)[0].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reullt1 and result2a are NOT exactly the same\n",
    "assert not np.array_equal(result1, result2a)\n",
    "\n",
    "# they are slightly different\n",
    "assert np.allclose(result1, result2b, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result2a and result2b are the same\n",
    "assert np.array_equal(result2a, result2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `result3` has a different shape, because the sequence was padded to the longer sequence in the list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3_paddings_removed = result3[:147, :]\n",
    "# the actual embeddings between result1 and result3 are NOT exactly the same\n",
    "assert not np.array_equal(result1, result3_paddings_removed)\n",
    "\n",
    "# they are slightly different\n",
    "assert np.allclose(result1[1:146, :], result3[1:146, :], atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run N=1 Batch\n",
    "\n",
    "We will run N=1 batch for 10 times on the same protein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "# running inference 10 time\n",
    "for n in range(N): \n",
    "\t# but each time, we only embed 1 smiles\n",
    "    result = predict(input1)[0].cpu()\n",
    "    # this generates exactly the same array per round\n",
    "    assert np.array_equal(result1, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the same protein, if we run N=1 batch, the result is **deterministic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**: Similar to the ESM2nv, to ensure that the embeddings are exactly same from each round, submit one protein sequence for each query, instead of putting them into a list. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
