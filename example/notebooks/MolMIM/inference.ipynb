{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPDX-FileCopyrightText: Copyright (c) <year> NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "SPDX-License-Identifier: LicenseRef-NvidiaProprietary\n",
    "\n",
    "NVIDIA CORPORATION, its affiliates and licensors retain all intellectual property and proprietary rights in and to this material, related documentation and any modifications thereto. Any use, reproduction, disclosure or distribution of this material and related documentation without an express license agreement from NVIDIA CORPORATION or its affiliates is strictly prohibited.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "**Before diving in, ensure you have all [necessary prerequisites](https://docs.nvidia.com/bionemo-framework/latest/pre-reqs.html). If this is your first time using BioNeMo, we recommend following the [quickstart guide](https://docs.nvidia.com/bionemo-framework/latest/quickstart-fw.html) first.** \n",
    "\n",
    "Additionally, this notebook assumes you have started a [local inference server](https://docs.nvidia.com/bionemo-framework/latest/inference-triton-fw.html) using a pretrained [MegaMolBART](https://docs.nvidia.com/bionemo-framework/latest/models/megamolbart.html) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.1.0a0+32f93b1 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-05-21 21:19:37 megatron_hiddens:110] Registered hidden transform sampled_var_cond_gaussian at bionemo.model.core.hiddens_support.SampledVarGaussianHiddenTransform\n",
      "[NeMo I 2024-05-21 21:19:37 megatron_hiddens:110] Registered hidden transform interp_var_cond_gaussian at bionemo.model.core.hiddens_support.InterpVarGaussianHiddenTransform\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from bionemo.triton.inference_wrapper import new_inference_wrapper\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0521 21:19:43.634553 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n",
      "W0521 21:19:43.657920 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n",
      "W0521 21:19:43.658641 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n",
      "W0521 21:19:43.659281 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n",
      "W0521 21:19:43.660974 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n",
      "W0521 21:19:43.661570 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n",
      "W0521 21:19:43.662192 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n",
      "W0521 21:19:43.662809 140476867809920 client.py:184] tritonclient.grpc doesn't support timeout for other commands than infer. Ignoring network_timeout: 60.0.\n"
     ]
    }
   ],
   "source": [
    "connection = new_inference_wrapper(\"grpc://localhost:8001\")\n",
    "\n",
    "smis = [\n",
    "    'c1ccc2ccccc2c1',\n",
    "    'COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMILES to hidden state\n",
    "\n",
    "`seqs_to_hidden` queries the model to fetch the latent space representation of the SMILES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_states.shape=torch.Size([2, 1, 512])\n",
      "pad_masks.shape=torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "hidden_states, pad_masks = connection.seqs_to_hidden(smis)\n",
    "print(f\"{hidden_states.shape=}\")\n",
    "print(f\"{pad_masks.shape=}\")\n",
    "\n",
    "assert tuple(hidden_states.shape) == (2, 1, 512)\n",
    "assert tuple(pad_masks.shape) == (2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden state to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.shape=torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "embeddings = connection.hiddens_to_embedding(hidden_states, pad_masks)\n",
    "print(f\"{embeddings.shape=}\")\n",
    "assert tuple(embeddings.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMILES to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.shape=torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "embedding = connection.seqs_to_embedding(smis)\n",
    "print(f\"{embedding.shape=}\")\n",
    "assert tuple(embedding.shape) == (2, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden state to SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonicalize_smiles(smiles: str) -> str:\n",
    "    \"\"\"Canonicalize input SMILES\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    canon_smiles = Chem.MolToSmiles(mol, canonical=True)\n",
    "    return canon_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed SMILES:\n",
      "['c1ccc2ccccc2c1', 'COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC']\n"
     ]
    }
   ],
   "source": [
    "infered_smis = connection.hidden_to_seqs(hidden_states, pad_masks)\n",
    "canon_infered_smis = list(map(canonicalize_smiles, infered_smis))\n",
    "print(f\"Reconstructed SMILES:\\n{canon_infered_smis}\")\n",
    "assert len(canon_infered_smis) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 samples\n",
      "Sample #1 (length: 1):\n",
      "['c1ccc2c(c1)C[C@H](CN[C@H]1COC3(CCC3)C1)O2']\n",
      "-----------------------\n",
      "Sample #2 (length: 1):\n",
      "['COc1cc2nc(N3CCN(C(=O)C4CC4)CC3)nc(N(C)C)c2cc1OC']\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "samples = connection.sample_seqs(seqs=smis)\n",
    "print(f\"Generated {len(samples)} samples\")\n",
    "assert len(samples) == 2\n",
    "for i,s in enumerate(samples):\n",
    "    print(f\"Sample #{i+1} (length: {len(s)}):\\n{s}\\n-----------------------\")\n",
    "    assert len(s) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
